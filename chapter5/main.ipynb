{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read(path, file_name):\n",
    "    \"\"\"数据读取函数\n",
    "\n",
    "    Args:\n",
    "        path (str): 数据文件路径\n",
    "        file_name (str): 数据文件名\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(os.path.join(path, file_name), delim_whitespace=True, header=None)\n",
    "\n",
    "    columns = ['status_account', 'duration', 'credit_history', 'purpose', 'amount', 'svaing_account', 'present_emp', 'income_rate',\n",
    "            'personal_status', 'other_debtors', 'residence_info', 'property', 'age', 'inst_plans', 'housing', 'num_credits', 'job',\n",
    "            'dependents', 'telephone', 'foreign_worker', 'target']\n",
    "    df.columns = columns # 变量重命名\n",
    "\n",
    "    df.target =  df.target -1 # 将标签变量由状态1,2转换为0,1,0表示好用户，1表示坏用户\n",
    "\n",
    "    # 数据分为训练集和验证集，训练集用于得到编码函数，验证集用已知编码规则编码\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=0, stratify=df.target)\n",
    "\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), 'data')\n",
    "file_name = 'german.csv' \n",
    "data_train, data_test = data_read(file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不可排序变量\n",
    "var_no_order = ['credit_history', 'purpose', 'personal_status', 'other_debtors', 'inst_plans', 'housing', 'job', 'telephone', 'foreign_worker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(df, data_path, flag='train'):\n",
    "    \"\"\"one-hot 编码\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): [description]\n",
    "        data_path (str): [description]\n",
    "        flag (str, optional): [description]. Defaults to 'train'.\n",
    "    \"\"\"\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # 判断数据集是否存在缺失值\n",
    "    if sum(df.isnull().any()) > 0:\n",
    "        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "        var_numerics = df.select_dtypes(include=numerics).columns\n",
    "        var_str = [i for i in df.columns if i not in var_numerics]\n",
    "        if len(var_numerics) > 0:\n",
    "            df.loc[:,  var_numerics] = df[var_numerics].fillna(-77777) # 数值类型的缺失值用-77777填补\n",
    "        if len(var_str) > 0:\n",
    "            df.loc[:, var_str] = df[var_str].fillna('NA')\n",
    "\n",
    "    # 由训练集得到编码规则\n",
    "    if flag == 'train':\n",
    "        enc = OneHotEncoder().fit(df)\n",
    "        # 保存编码模型\n",
    "        save_model = open(os.path.join(data_path, 'onehot.pkl'), 'wb')\n",
    "        pickle.dump(enc, save_model, 0)\n",
    "        save_model.close()\n",
    "        df_return = pd.DataFrame(enc.transform(df).toarray())\n",
    "        df_return.columns = enc.get_feature_names(df.columns)\n",
    "\n",
    "    # 测试数据集编码\n",
    "    elif flag == 'test':\n",
    "        read_model = open(os.path.join(data_path, 'onehot.pkl'), 'rb')\n",
    "        onehot_model = pickle.load(read_model)\n",
    "        read_model.close()\n",
    "        # 如果训练集无缺失值，测试集有缺失值则将该样本删除\n",
    "        var_range = onehot_model.categories_\n",
    "        var_name = df.columns\n",
    "        del_index = []\n",
    "        for i in range(len(var_range)):\n",
    "            if 'NA' not in var_range[i] and 'NA' in df[var_name[i]].unique():\n",
    "                index = np.where(df[var_name[i]] == 'NA')\n",
    "                del_index.append(index)\n",
    "            elif -77777 not in var_range[i] and -77777 in df[var_name[i]].unique():\n",
    "                index = np.where(df[var_name[i] == -77777])\n",
    "                del_index.append(index)\n",
    "        # 删除样本\n",
    "        if len(del_index) > 0:\n",
    "            del_index = np.unique(del_index)\n",
    "            df = df.drop(del_index)\n",
    "            print('训练集无缺失值，但测试集有缺失值，第{0}条样本被删除'.format(del_index))\n",
    "        df_return = pd.DataFrame(onehot_model.transform(df).toarray())\n",
    "        df_return.columns = onehot_model.get_feature_names(df.columns)\n",
    "\n",
    "    # 编码数据值转化为原始变量\n",
    "    elif flag == 'transform':\n",
    "        read_model = open(os.path.join(data_path, 'onehot.pkl'), 'rb')\n",
    "        onehot_model = pickle.load(read_model)\n",
    "        read_model.close()\n",
    "        # 逆变换\n",
    "        df_return = pd.DataFrame(onehot_model.inverse_transform(df))\n",
    "        df_return.columns = np.unique(['_'.join(i.rsplit('_')[:-1]) for i in df.columns])\n",
    "\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据编码\n",
    "data_train.credit_history[882] = np.nan\n",
    "data_train_encode = onehot_encode(data_train[var_no_order], file_path, flag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试数据编码\n",
    "data_test.credit_history[529] = np.nan\n",
    "data_test.purpose[335] = np.nan \n",
    "data_test_encode = onehot_encode(data_test[var_no_order], file_path, flag='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看编码逆变换后的原始变量名\n",
    "df_encoded = data_test_encode.loc[0:4]\n",
    "data_inverse = onehot_encode(df_encoded, file_path, flag='transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 哑变量编码\n",
    "data_train_dummies = pd.get_dummies(data_train[var_no_order])\n",
    "data_test_dummies = pd.get_dummies(data_test[var_no_order])\n",
    "data_train_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可排序变量\n",
    "var_order = ['status_account', 'svaing_account', 'present_emp', 'property']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(df, data_path, flag='train'):\n",
    "    \"\"\"标签编码\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): 待处理数据集\n",
    "        data_path (str): 文件路径\n",
    "        flag (str, optional): 数据处理标识. Defaults to 'train'.\n",
    "    \"\"\"\n",
    "    if flag == 'train':\n",
    "        enc = LabelEncoder().fit(df)\n",
    "        # 保存编码模型\n",
    "        save_model = open(os.path.join(data_path, 'labelcode.pkl'), 'wb')\n",
    "        pickle.dump(enc, save_model, 0)\n",
    "        save_model.close()\n",
    "        df_return = pd.DataFrame(enc.transform(df))\n",
    "        df_return.name = df.name\n",
    "\n",
    "    # 测试数据编码\n",
    "    elif flag == 'test':\n",
    "        read_model = open(os.path.join(data_path, 'labelcode.pkl'), 'rb')\n",
    "        label_model = pickle.load(read_model)\n",
    "        read_model.close()\n",
    "        df_return = pd.DataFrame(label_model.transform(df))\n",
    "        df_return.name = df.name\n",
    "    #编码数据转化成原始变量\n",
    "    elif flag == 'transform':\n",
    "        read_model = open(os.path.join(data_path, 'labelcode.pkl'), 'rb')\n",
    "        label_model = pickle.load(read_model)\n",
    "        read_model.close()\n",
    "        # 逆变换\n",
    "        df_return = pd.DataFrame(label_model.inverse_transform(df))\n",
    "\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据编码\n",
    "data_train_encode = label_encode(data_train[var_order[1]], file_path, flag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证数据编码\n",
    "data_test_encode = label_encode(data_test[var_order[1]], file_path, flag='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = data_test_encode\n",
    "data_inverse = label_encode(df_encoded, file_path, flag='transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_encode(df, data_path):\n",
    "    \"\"\"自定义映射\n",
    "\n",
    "    Args:\n",
    "        df ([type]): [description]\n",
    "        data_path ([type]): [description]\n",
    "    \"\"\"\n",
    "    embarked_mapping = {}\n",
    "    embarked_mapping['status_account'] = {'NA': 1, 'A14': 2, 'A11':3,'A12': 4,'A13':5}  \n",
    "    embarked_mapping['svaing_account'] = {'NA': 1, 'A65': 1, 'A61':3,'A62': 5,'A63':6,'A64':8}  \n",
    "    embarked_mapping['present_emp'] = {'NA': 1, 'A71': 2, 'A72':5,'A73': 6,'A74':8,'A75':10}  \n",
    "    embarked_mapping['property'] = {'NA': 1, 'A124': 1, 'A123':4,'A122': 6, 'A121':9 }\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    # 判断数据集是否存在缺失值\n",
    "    if sum(df.isnull().any()) > 0:\n",
    "        df = df.fillna('NA')\n",
    "\n",
    "    # 字典映射\n",
    "    var_dictEncode = []\n",
    "    for i in df.columns:\n",
    "        col = i + '_dictEncode'\n",
    "        df[col] = df[i].map(embarked_mapping[i])\n",
    "        var_dictEncode.append(col)\n",
    "    return df[var_dictEncode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据编码\n",
    "data_train.credit_history[882] = np.nan\n",
    "data_train_encode = dict_encode(data_train[var_order], file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试数据编码\n",
    "data_test.status_account[529] = np.nan\n",
    "data_test_encode = dict_encode(data_test[var_order], file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_cal_trans(x, y, target=1):\n",
    "    \"\"\"WOE编码\n",
    "\n",
    "    Args:\n",
    "        x ([type]): [description]\n",
    "        y ([type]): [description]\n",
    "        target (int, optional): [description]. Defaults to 1.\n",
    "    \"\"\"\n",
    "    # 计算总体的正负样本数\n",
    "    p_total = sum(y == target)\n",
    "    n_total = len(x) - p_total\n",
    "    value_num = list(x.unique())\n",
    "    woe_map = {}\n",
    "    iv_value = 0\n",
    "    for i in value_num:\n",
    "        # 计算该变量取值箱内的正负样本总数\n",
    "        y1 = y[np.where(x==i)[0]]\n",
    "        p_num_1 = sum(y1 == target)\n",
    "        n_num_1 = len(y1) - p_num_1\n",
    "        # 计算占比\n",
    "        bad_1 = p_num_1 / p_total\n",
    "        good_1 = n_num_1 / n_total\n",
    "        if bad_1 == 0:\n",
    "            bad_1 = 1e-5\n",
    "        elif good_1 == 0:\n",
    "            goog_1 = 1e-5\n",
    "        woe_map[i] = np.log(bad_1 / good_1)\n",
    "        iv_value += (bad_1 - good_1) * woe_map[i]\n",
    "    x_woe_trans = x.map(woe_map)\n",
    "    x_woe_trans.name = x.name + '_woe'\n",
    "    \n",
    "    return x_woe_trans, woe_map, iv_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_encode(df, data_path, varnames, y, filename, flag='train'):\n",
    "    \"\"\"WOE编码映射\n",
    "\n",
    "    Args:\n",
    "        df ([type]): [description]\n",
    "        data_path ([type]): [description]\n",
    "        varnames ([type]): [description]\n",
    "        y ([type]): [description]\n",
    "        filename ([type]): [description]\n",
    "        flag (str, optional): [description]. Defaults to 'train'.\n",
    "    \"\"\"\n",
    "    df = df.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "\n",
    "    # 判断数据集是否存在缺失值\n",
    "    if sum(df.isnull().any()) > 0:\n",
    "        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "        var_numerics = df.select_dtypes(include=numerics).columns\n",
    "        var_str = [i for i in df.columns if i not in var_numerics]\n",
    "        if len(var_numerics) > 0:\n",
    "            df.loc[:,  var_numerics] = df[var_numerics].fillna(-77777) # 数值类型的缺失值用-77777填补\n",
    "        if len(var_str) > 0:\n",
    "            df.loc[:, var_str] = df[var_str].fillna('NA')\n",
    "\n",
    "    if flag == 'train':\n",
    "        iv_values, woe_maps = {}, {}\n",
    "        var_woe_name = []\n",
    "        for var in varnames:\n",
    "            x = df[var]\n",
    "            # 变量映射\n",
    "            x_woe_trans, woe_map, info_value = woe_cal_trans(x, y)\n",
    "            var_woe_name.append(x_woe_trans.name)\n",
    "            df = pd.concat([df, x_woe_trans], axis=1)\n",
    "            woe_maps[var] = woe_map\n",
    "            iv_values[var] = info_value\n",
    "        # 保存WOE映射字典\n",
    "        save_woe_dict = open(os.path.join(data_path, filename + '.pkl'), 'wb')\n",
    "        pickle.dump(woe_maps, save_woe_dict, 0)\n",
    "        save_woe_dict.close()\n",
    "        return df, woe_maps, iv_values, var_woe_name\n",
    "\n",
    "    # 测试数据编码\n",
    "    elif flag == 'test':\n",
    "        read_woe_dict = open(os.path.join(data_path, filename + '.pkl'), 'rb')\n",
    "        woe_dict = pickle.load(read_woe_dict)\n",
    "        read_woe_dict.close()\n",
    "        # 如果训练集无缺失值，测试集有缺失值则将该样本删除\n",
    "        woe_dict.keys()\n",
    "        del_index = []\n",
    "        for key, value in woe_dict.items():\n",
    "            if 'NA' not in value.keys() and -77777 in df[key].unique():\n",
    "                index = np.where(df[key] == 'NA')\n",
    "                del_index.append(index)\n",
    "            elif -77777 not in value.keys() and -77777 in df[key].unique():\n",
    "                index = np.where(df[key] == -77777)\n",
    "                del_index.append(index)\n",
    "        # 删除样本\n",
    "        if len(del_index) > 0:\n",
    "            del_index = np.unique(del_index)\n",
    "            df = df.drop(del_index)\n",
    "            print('训练集无缺失值，但测试集有缺失值，该样本{0}删除'.format(del_index))\n",
    "        # WOE编码映射\n",
    "        var_woe_name = []\n",
    "        for key, value in woe_dict.items():\n",
    "            val_name = key + '_woe' \n",
    "            df[val_name] = df[key].map(value)\n",
    "            var_woe_name.append(val_name)\n",
    "        return df, var_woe_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集编码\n",
    "df_train_woe, dict_woe_map, dict_iv_values, var_woe_name = woe_encode(data_train, file_path, var_no_order, data_train.target, 'dict_woe_map', flag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集编码\n",
    "df_test_woe, var_woe_name = woe_encode(data_test, file_path, var_no_order, data_train.target, 'dict_woe_map', flag='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4027a6336bc1541d1b89071d8afeb287e065fbc38311cf264ccc3ebf86fa9ab8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
